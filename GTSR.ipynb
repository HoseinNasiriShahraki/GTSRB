{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/hosei/Documents/DataSets/GTSRB\"\n",
    "train_path = \"C:/Users/hosei/Documents/DataSets/GTSRB/Train/\"\n",
    "test_path = \"C:/Users/hosei/Documents/DataSets/GTSRB/Test/\"\n",
    "meta_path = \"C:/Users/hosei/Documents/DataSets/GTSRB/Meta/\"\n",
    "\n",
    "meta_df = pd.read_csv('C:/Users/hosei/Documents/DataSets/GTSRB/Meta.csv')\n",
    "train_df = pd.read_csv('C:/Users/hosei/Documents/DataSets/GTSRB/Train.csv')\n",
    "test_df = pd.read_csv('C:/Users/hosei/Documents/DataSets/GTSRB/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parametes\n",
    "num_of_classes = len(os.listdir(train_path))\n",
    "height = 30\n",
    "width = 30\n",
    "channels = 3\n",
    "n_inputs = height * width * num_of_classes\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #data Visualation\n",
    "# folder_names = [os.path.join(train_path, str(i)) for i in random.choices(range(43), k=20)] \n",
    "# file_names = [os.path.join(fldr, os.listdir(fldr)[0]) for fldr in folder_names]\n",
    "\n",
    "# fig, axes = plt.subplots(4, 5, figsize=(12, 8))\n",
    "# for i, image_path in enumerate(file_names):\n",
    "#     image = Image.open(image_path)\n",
    "#     row = i // 5\n",
    "#     col = i % 5\n",
    "#     axes[row, col].imshow(image)\n",
    "#     axes[row, col].axis('off')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Data ToTensor and Normalize it + resize to 28*28\n",
    "\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Resize((28,28)),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "#creating the dataset class\n",
    "class GTSR_DataSet(Dataset):\n",
    "    def __init__(self, df, root_dir,transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image_path = os.path.join(self.root_dir,self.df.iloc[index,7])  #the column of paths in dataframe is 7\n",
    "        image = Image.open(image_path)\n",
    "        y_class = torch.tensor(self.df.iloc[index, 6]) #the column of ClsassId in daraframe is 6\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            return (image, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = GTSR_DataSet(train_df,data_dir,transform=transforms)\n",
    "test_set = GTSR_DataSet(test_df,data_dir,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 39209, 'testing': 12630}\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset = training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {'training':train_loader,'testing':test_loader}\n",
    "dataset_sizes = {'training':len(train_loader.dataset),'testing':len(test_loader.dataset)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "class GTRSB_Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(GTRSB_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        # self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1)\n",
    "        # self.batchnorm3 = nn.BatchNorm2d(1024)\n",
    "        # self.maxpool3 = nn.AdaptiveMaxPool2d(512)\n",
    "\n",
    "        \n",
    "        self.l1 = nn.Linear(12544,512)\n",
    "        self.l2 = nn.Linear(512,128)\n",
    "        self.batchnorm4 = nn.LayerNorm(128)\n",
    "        self.l3 = nn.Linear(128,output_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        #training pipeline\n",
    "\n",
    "        conv = self.conv1(input)\n",
    "        conv = self.conv2(conv)\n",
    "\n",
    "        batchnorm = self.relu(self.batchnorm1(conv))\n",
    "        maxpool = self.maxpool(batchnorm)\n",
    "\n",
    "        conv = self.conv3(maxpool)\n",
    "        conv = self.conv4(conv)\n",
    "\n",
    "        batchnorm = self.relu(self.batchnorm2(conv))\n",
    "        maxpool = self.maxpool(batchnorm)\n",
    "\n",
    "        # conv = self.conv5(maxpool)\n",
    "        # conv = self.conv6(conv)\n",
    "        # batchnorm = self.relu(self.batchnorm3(conv))\n",
    "        # maxpool = self.maxpool3(batchnorm)\n",
    "    \n",
    "\n",
    "              \n",
    "        flatten = self.flatten(maxpool)\n",
    "        \n",
    "        #Neural Network Featuremap input\n",
    "        dense_l1 = self.l1(flatten)\n",
    "        dropout = self.dropout3(dense_l1)\n",
    "        dense_l2 = self.l2(dropout)\n",
    "        batchnorm = self.batchnorm4(dense_l2)\n",
    "        dropout = self.dropout2(batchnorm)\n",
    "        output = self.l3(dropout)\n",
    "        \n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTRSB_Model(\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (dropout3): Dropout(p=0.3, inplace=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l1): Linear(in_features=12544, out_features=512, bias=True)\n",
       "  (l2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (batchnorm4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (l3): Linear(in_features=128, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 3*28*28\n",
    "output_size = 43\n",
    "model = GTRSB_Model(input_size=input_size, output_size=output_size)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hosei\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10, SGD accuracy = 91.07680126682503\n",
      "epoch 2 / 10, SGD accuracy = 93.95882818685669\n",
      "epoch 3 / 10, SGD accuracy = 95.49485352335708\n",
      "epoch 4 / 10, SGD accuracy = 95.53444180522565\n",
      "epoch 5 / 10, SGD accuracy = 95.71654790182106\n",
      "epoch 6 / 10, SGD accuracy = 96.27870150435471\n",
      "epoch 7 / 10, SGD accuracy = 96.3341250989707\n",
      "epoch 8 / 10, SGD accuracy = 96.41330166270784\n",
      "epoch 9 / 10, SGD accuracy = 96.40538400633413\n",
      "epoch 10 / 10, SGD accuracy = 96.57957244655582\n",
      "---------------------------------\n",
      "epoch 1 / 10, ADAM accuracy = 94.48139350752177\n",
      "epoch 2 / 10, ADAM accuracy = 95.63737133808394\n",
      "epoch 3 / 10, ADAM accuracy = 95.23357086302454\n",
      "epoch 4 / 10, ADAM accuracy = 94.98020585906572\n",
      "epoch 5 / 10, ADAM accuracy = 95.81947743467933\n",
      "epoch 6 / 10, ADAM accuracy = 95.89865399841648\n",
      "epoch 7 / 10, ADAM accuracy = 94.64766429136976\n",
      "epoch 8 / 10, ADAM accuracy = 95.57403008709421\n",
      "epoch 9 / 10, ADAM accuracy = 97.06254948535233\n",
      "epoch 10 / 10, ADAM accuracy = 96.04908946951703\n",
      "---------------------------------\n",
      "epoch 1 / 10, ASGD accuracy = 96.31037212984957\n",
      "epoch 2 / 10, ASGD accuracy = 96.326207442597\n",
      "epoch 3 / 10, ASGD accuracy = 96.57165479018211\n",
      "epoch 4 / 10, ASGD accuracy = 96.48456057007125\n",
      "epoch 5 / 10, ASGD accuracy = 96.54790182106096\n",
      "epoch 6 / 10, ASGD accuracy = 96.55581947743468\n",
      "epoch 7 / 10, ASGD accuracy = 96.65874901029295\n",
      "epoch 8 / 10, ASGD accuracy = 96.70625494853523\n",
      "epoch 9 / 10, ASGD accuracy = 96.78543151227237\n",
      "epoch 10 / 10, ASGD accuracy = 96.66666666666667\n",
      "---------------------------------\n",
      "epoch 1 / 10, Adadelta accuracy = 96.66666666666667\n",
      "epoch 2 / 10, Adadelta accuracy = 96.69833729216151\n",
      "epoch 3 / 10, Adadelta accuracy = 96.60332541567695\n",
      "epoch 4 / 10, Adadelta accuracy = 96.83293745051465\n",
      "epoch 5 / 10, Adadelta accuracy = 96.71417260490894\n",
      "epoch 6 / 10, Adadelta accuracy = 96.8012668250198\n",
      "epoch 7 / 10, Adadelta accuracy = 96.70625494853523\n",
      "epoch 8 / 10, Adadelta accuracy = 96.75376088677751\n",
      "epoch 9 / 10, Adadelta accuracy = 96.71417260490894\n",
      "epoch 10 / 10, Adadelta accuracy = 96.72209026128266\n",
      "---------------------------------\n",
      "epoch 1 / 10, Adagrad accuracy = 97.36342042755345\n",
      "epoch 2 / 10, Adagrad accuracy = 97.37925574030088\n",
      "epoch 3 / 10, Adagrad accuracy = 97.41884402216944\n",
      "epoch 4 / 10, Adagrad accuracy = 97.513855898654\n",
      "epoch 5 / 10, Adagrad accuracy = 97.42676167854314\n",
      "epoch 6 / 10, Adagrad accuracy = 97.64845605700712\n",
      "epoch 7 / 10, Adagrad accuracy = 97.59303246239112\n",
      "epoch 8 / 10, Adagrad accuracy = 97.70387965162311\n",
      "epoch 9 / 10, Adagrad accuracy = 97.6959619952494\n",
      "epoch 10 / 10, Adagrad accuracy = 97.70387965162311\n",
      "---------------------------------\n",
      "epoch 1 / 10, AdamW accuracy = 97.2763262074426\n",
      "epoch 2 / 10, AdamW accuracy = 96.0332541567696\n",
      "epoch 3 / 10, AdamW accuracy = 96.31037212984957\n",
      "epoch 4 / 10, AdamW accuracy = 96.59540775930324\n",
      "epoch 5 / 10, AdamW accuracy = 97.31591448931115\n",
      "epoch 6 / 10, AdamW accuracy = 97.61678543151227\n",
      "epoch 7 / 10, AdamW accuracy = 95.47901821060965\n",
      "epoch 8 / 10, AdamW accuracy = 97.26840855106889\n",
      "epoch 9 / 10, AdamW accuracy = 96.95170229612035\n",
      "epoch 10 / 10, AdamW accuracy = 96.98337292161521\n",
      "---------------------------------\n",
      "epoch 1 / 10, Adamax accuracy = 98.08392715756136\n",
      "epoch 2 / 10, Adamax accuracy = 98.06017418844021\n",
      "epoch 3 / 10, Adamax accuracy = 98.24228028503563\n",
      "epoch 4 / 10, Adamax accuracy = 98.29770387965162\n",
      "epoch 5 / 10, Adamax accuracy = 98.33729216152018\n",
      "epoch 6 / 10, Adamax accuracy = 98.37688044338876\n",
      "epoch 7 / 10, Adamax accuracy = 98.49564528899447\n",
      "epoch 8 / 10, Adamax accuracy = 98.27395091053049\n",
      "epoch 9 / 10, Adamax accuracy = 98.44813935075217\n",
      "epoch 10 / 10, Adamax accuracy = 98.36104513064133\n",
      "---------------------------------\n",
      "epoch 1 / 10, NAdam accuracy = 95.7957244655582\n",
      "epoch 2 / 10, NAdam accuracy = 95.8590657165479\n",
      "epoch 3 / 10, NAdam accuracy = 96.88836104513065\n",
      "epoch 4 / 10, NAdam accuracy = 96.56373713380839\n",
      "epoch 5 / 10, NAdam accuracy = 96.82501979414093\n",
      "epoch 6 / 10, NAdam accuracy = 97.49802058590657\n",
      "epoch 7 / 10, NAdam accuracy = 97.04671417260491\n",
      "epoch 8 / 10, NAdam accuracy = 97.30007917656374\n",
      "epoch 9 / 10, NAdam accuracy = 97.49802058590657\n",
      "epoch 10 / 10, NAdam accuracy = 97.53760886777513\n",
      "---------------------------------\n",
      "epoch 1 / 10, RAdam accuracy = 97.65637371338084\n",
      "epoch 2 / 10, RAdam accuracy = 97.88598574821853\n",
      "epoch 3 / 10, RAdam accuracy = 95.40775930324624\n",
      "epoch 4 / 10, RAdam accuracy = 96.65874901029295\n",
      "epoch 5 / 10, RAdam accuracy = 97.61678543151227\n",
      "epoch 6 / 10, RAdam accuracy = 97.70387965162311\n",
      "epoch 7 / 10, RAdam accuracy = 96.61124307205067\n",
      "epoch 8 / 10, RAdam accuracy = 97.20506730007918\n",
      "epoch 9 / 10, RAdam accuracy = 97.41884402216944\n",
      "epoch 10 / 10, RAdam accuracy = 97.89390340459224\n",
      "---------------------------------\n",
      "epoch 1 / 10, RMSprop accuracy = 96.6825019794141\n",
      "epoch 2 / 10, RMSprop accuracy = 96.3895486935867\n",
      "epoch 3 / 10, RMSprop accuracy = 96.95170229612035\n",
      "epoch 4 / 10, RMSprop accuracy = 97.33174980205858\n",
      "epoch 5 / 10, RMSprop accuracy = 97.6959619952494\n",
      "epoch 6 / 10, RMSprop accuracy = 97.64053840063342\n",
      "epoch 7 / 10, RMSprop accuracy = 97.3396674584323\n",
      "epoch 8 / 10, RMSprop accuracy = 97.60886777513856\n",
      "epoch 9 / 10, RMSprop accuracy = 97.1021377672209\n",
      "epoch 10 / 10, RMSprop accuracy = 97.34758511480601\n",
      "---------------------------------\n",
      "epoch 1 / 10, Rprop accuracy = 96.06492478226446\n",
      "epoch 2 / 10, Rprop accuracy = 95.69279493269993\n",
      "epoch 3 / 10, Rprop accuracy = 94.33887569279493\n",
      "epoch 4 / 10, Rprop accuracy = 94.57640538400634\n",
      "epoch 5 / 10, Rprop accuracy = 93.18289786223278\n",
      "epoch 6 / 10, Rprop accuracy = 92.50197941409343\n",
      "epoch 7 / 10, Rprop accuracy = 93.11955661124307\n",
      "epoch 8 / 10, Rprop accuracy = 91.79730799683293\n",
      "epoch 9 / 10, Rprop accuracy = 91.44893111638956\n",
      "epoch 10 / 10, Rprop accuracy = 91.97941409342835\n"
     ]
    }
   ],
   "source": [
    "# model deployment with SGD Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate , momentum=0.9)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, SGD accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# model deployment with Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, ADAM accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# model deployment with ASGD Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.ASGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, ASGD accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model deployment with Adadelta Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate , rho=0.9)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, Adadelta accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "# model deployment with Adagrad Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, Adagrad accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "        \n",
    "        \n",
    "# model deployment with AdamW Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, AdamW accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# model deployment with Adamax Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, Adamax accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")        \n",
    "\n",
    "        \n",
    "# model deployment with NAdam Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, NAdam accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "        \n",
    "# model deployment with RAdam Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, RAdam accuracy = {acc}')\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"---------------------------------\")\n",
    "\n",
    "        \n",
    "# model deployment with RMSprop Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, RMSprop accuracy = {acc}')\n",
    "        \n",
    "\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "        \n",
    "        \n",
    "# model deployment with Rprop Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Rprop(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images, labels = images.type(torch.LongTensor), labels.type(torch.LongTensor)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 500 == 0:\n",
    "        #     print(f'epoch {epoch+1} / {num_epochs}, step {i+1}, loss = {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples +=labels.shape[0]\n",
    "            n_correct +=(predictions == labels).sum().item()\n",
    "        acc = 100.0 * (n_correct / n_samples)\n",
    "        print(f'epoch {epoch+1} / 10, Rprop accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
